{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cad370d-e390-4f7c-b986-a2a0827184af",
   "metadata": {},
   "source": [
    "Este script se utiliza para realizar las predicciones y dockerizar es decir guardar en la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be530c4b-d6c4-406b-943e-f47eaefa5581",
   "metadata": {},
   "source": [
    "importaciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a356e4dc-f5f9-4230-ab3a-9013b08eb3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import cv2\n",
    "from numpy import argmax\n",
    "from pymongo import MongoClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b476d50-7dcb-46ae-b4bd-f4b55363f835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd10475f-0601-4a0a-9a47-48fbfcce7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\t# Conectar a la db, host y puerto\n",
    "\tconn = MongoClient(host='localhost', port=27017)\n",
    "\t# Obtener base de datos\n",
    "\tdb = conn.local\n",
    "except:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8ab70-a995-411e-97e2-8072a0e7aee4",
   "metadata": {},
   "source": [
    "Definir el modelo de la red neuronal para cargarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3724d22a-529e-4b88-925b-3b5d7843cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir modelo\n",
    "class scratch_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=100, kernel_size=5, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(100, 200, 3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(200, 400, 3, stride=1, padding=0)\n",
    "        self.mpool = nn.MaxPool2d(kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(19600,1024)\n",
    "        self.linear2 = nn.Linear(1024,512)\n",
    "        self.linear3 = nn.Linear(512,2)\n",
    "        self.classifier = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.mpool( self.relu(self.conv1(x)) )\n",
    "        x = self.mpool( self.relu(self.conv2(x)) )\n",
    "        x = self.mpool( self.relu(self.conv3(x)) )\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559bf6f8-7db1-4c2b-adce-2af3eed98129",
   "metadata": {},
   "source": [
    "Cargamos los parametros que ha aprendido  \n",
    "Se hace hincapie en que como no estamos entrenando se hace en modo evaluacion-->.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84c9017-22ad-4e30-97ef-a8b19d559e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo entrenado\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = scratch_nn()\n",
    "model.load_state_dict(torch.load(\"dogs_cats_model.pth\"))\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef847918-8344-4c58-8271-81342130a339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89f2d834-3f0c-412a-b7e5-d08f11b2b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir preprocesados de la imagen\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef911a0-05e1-4259-a9b0-de647a9e306e",
   "metadata": {},
   "source": [
    "Realizar las predicciones de la carpeta con las 10 imagenes y asi ver los resultados de la red neuronal y ver si predice bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c0ba0c5-9f18-469a-a54c-c418384d8121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Dog\n",
      "Predicted label: Dog\n",
      "Predicted label: Dog\n",
      "Predicted label: Dog\n",
      "Predicted label: Dog\n",
      "Predicted label: Dog\n",
      "Predicted label: Dog\n",
      "Predicted label: Dog\n",
      "Predicted label: Dog\n",
      "Predicted label: Dog\n"
     ]
    }
   ],
   "source": [
    "labels = [\"Cat\", \"Dog\"]\n",
    "for image_path in glob.glob(\"predict_cat_dog/*.jpg\"):\n",
    "\timg_orig = cv2.imread(image_path)\n",
    "\timg = data_transform(img_orig).unsqueeze(0).to(device)\n",
    "\toutputs = model(img)\n",
    "\toutputs = outputs.detach().cpu().numpy()\n",
    "\toutput = argmax(outputs, axis=1)[0]\n",
    "\tprint(\"Predicted label: \"+labels[output])\n",
    "\tcv2.imshow(\"Predicted label: \"+labels[output], img_orig)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()\n",
    "\t# Almacenar en base de datos\n",
    "\ttry:\n",
    "\t\tdb.data.insert_one({\"path_img\": image_path, \"predicted_label\": labels[output]})\n",
    "\texcept:\n",
    "\t\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcfd12e-e4a1-4eb8-8f71-b14a33b88d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
